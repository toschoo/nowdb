\section{Outline}
\sql\ is a language to store, manipulate
and query data in a database; traditionally
\sql\ is used with relational databases.
In recent years, however, people have
started to use \sql\ also in other contexts,
such as \term{graph} and \term{timeseries}
databases and new patterns are evolving
in the language to better address those
data models.

\sql\ consists of statements that,
in their turn, consist of clauses.
A statement is a piece of \sql\ code
that by itself constitutes a meaningful
action in the database. Statements are
distinguished in

\begin{itemize}
\item \acronym{ddl}:
Statements that create, drop or alter entities
in the database that hold or define
data
like tables, types, edges, indices,
functions or procedures.

\item \acronym{dml}:
Statements that manipulate data,
\eg\ \term{insert}, \term{update} and
\term{delete}.

\item \acronym{dll}:
Statements that load large volumes of data into the database
or retrieve large volumes of data from the database.

\item \acronym{dql}:
Statements that read data from the database.

\item Miscellaneous:
Statements that do not fall into any
those categories, in particular
\term{use} and \term{exec}.
\end{itemize}

Clauses are parts of statements;
a \acronym{dql} statement, for instance,
typically has a \term{select} clause and
a \term{from} clause and may have
additional clauses (\term{where},
\term{order by}, \term{group by} and so on).

Some clauses can appear in more than
one type of statement. \term{update}
and \term{delete} statements, typically,
have a \term{where} clause, but no
\term{select} clause.

Clauses can be seen as logical building blocks
of \sql. But they cannot live alone.
It is not possible to execute an isolated \term{where}
clause or an isolated \term{from} clause.
The smallest executable unit is therefore the statement.

Clauses are made of keywords, identifiers, numbers, text,
symbols (such as ``$, \dot = ( ) * + -$'') and
whitespace, \ie\ \acronym{ascii}
10 (line break),
13 (carriage return),
9  (horizontal tab)
and 32 (space).

Keywords and identifiers are mutually
exclusive, that is, if $k$ is a keyword,
$k$ cannot be an identifier at the same time.
\comment{This rule is relaxed in most
\sql\ dialects -- and that is a great relief for users,
because \sql\ has an extraordinary large
number of keywords which sometimes makes the choice
of meaningful identifiers a non-trivial task.
At the time of writing, the \nowdb\ parser
does not yet relax this rule, but it will do so
in the future.}
Keywords are defined by the \sql\ specification,
identifiers are chosen by the user
and refer to entities in the database,
such as tables, types, indices, \etc\

In this specification,
keywords are typeset in boldface
(\eg\ \keyword{table});
identifiers are typeset in italics
(like `mytable' in 
``\keyword{create table} \identifier{mytable}'').

\sql\ is a textual interface.
All statements that are passed to the database
have a textual form. The results produced
by the database, however, are not. They are
binary data which may or may not
contain textual elements.

In \nowdb\ \sql\ statements are strings
of \acronym{utf}-8 characters.
Keywords, identifiers and numbers, however,
must contain only characters
from the \acronym{ascii} subset.
Identifiers are further restricted:
They must start with an \acronym{ascii} 
Latin alphabetic ($a\dots z$ or $A \dots Z$)
and must contain only
alphanumerics or the underscore ($\_$).

Text, by contrast, may contain any
\acronym{utf}-8 character.
\comment{It is already possible to store
\acronym{utf}-8 in the database.
But comparison and sorting are not yet
\acronym{utf}-compliant. This is an
urgent to-do.}

Keywords and identifiers are case-insensitive.
There is no difference between
`\acronym{select}', `select' or `Select'
and so on.
Text, by contrast, is case-sensitive;
`hello world' and `hello World'
are not the same thing!

\sql\ is a \term{guest} language
that needs some kind of framework
to support it. One way to provide this
framework is the \nowdb\ client,
which provides two means to execute
\sql\ statements in the database,
\ie\ by means of the \tech{-Q} parameter
and by means of standard input.

Another way is a host language
that provides means to pass \sql\ statements
to the database and means to receive
and interpret the results produced by such statements.
For \nowdb, Python, C, Go and Lua (\comment{Go and Lua not yet})
are available as host languages.

The protocol that defines how data are exchanged
between the database and the host system
is not part of this specification.
Currently, native client and server libraries
exist that implement this protocol
without exposing it to the user.
To support open standards in the future, such as
\acronym{odbc} and \acronym{jdbc},
parts of this protocol must be documented
and published.

\section{Types}
A fundamental part of most languages
is their type system. \nowdb\ \sql\
has a very simple type system,
which is static and safe.
This type system is used to design
the database and to word
\sql\ statements.
We usually refer to it as the \sql\ Static Types.

However, since \sql\ is executed
in a host environment, there is a second
type system to describe the \term{results}
of \sql\ statements.
This other type system is even simpler --
it, in fact, consists of only one type.
This other type system, however, is dynamic.
It is therefore called \sql\ Dynamic Types.

In the following, we first present
the Static System and then the Dynamic System.

\subsection{Static Types}
The static types constitute the \nowdb\ \sql\ type system.
The static types can be used in \sql\ statements.
Each type is equipped with a declaration form and
type constructors that create instances of those types.

The declaration form is used in \acronym{ddl} statements
to define types, edges, procedure and functions.
In \acronym{dml}, \acronym{dll} and \acronym{dql} statements,
instances of the types are used, \ie\
types are not explicitly declared, but used implicitly
by means of their constructors, which are sufficient
to determine the type uniquely.

In the case of numeric types
(integers, unsigned integers and floats),
\nowdb\ silently corrects type mismatches where possible.
An unsigned integer inserted into a field where
a signed integer is expected, is implicitly converted
to an integer; correspondingly a signed integer
is converted to an unsigned integer if possible.
If the unsigned integer is out of range or
the signed integer is negative, the statement
is rejected with a type error.

Likewise, signed or unsigned integers are converted to floats
if necessary (and possible) and a float might be converted
to an integer (or unsigned integer) if it actually
represents an integer.

The static types are

\ignore{
\bgroup
\renewcommand{\arraystretch}{1.3}
\begin{center}
\begin{tabular}{||c||c||c||c||c||}\hline
Type & Declaration & Range & Constructor & Examples \\\hline\hline
Integer & $int$, $integer$ & $-2^{63} \dots 2^{63}-1$ & $\pm n$ & $-1, +0, +1$\\
        & &                & where $n$ is an unsigned ingeger & \\\cline{1-5}
Unsigned Integer & $uint$, $uinteger$ & $0 \dots 2^{64}-1$ & One digit $(0\dots 9)$ & $0, 1,2, 1024$\\
        & &                & or one digit $(1\dots 9)$ & but not: $01$\\
        & &                & followed by a sequence of digits ($0\dots9$). & \\\cline{1-5}
\end{tabular}
\end{center}
\egroup
}

\begin{minipage}{\textwidth}
\textbf{Integer}\\
Declaration: $int$, $integer$ \\
Values: $-2^{63} \dots 2^{63}-1$ \\
Constructors: $\pm n$, where $n$ is an unsigned integer.\\
Examples: $-1, +0, +1$
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Unsigned Integer} \\
Declaration: $uint$, $uinteger$ \\
Values: $0 \dots 2^{64}-1$  \\
Constructors: One digit from the range $0\dots 9$
or one digit from range $1\dots 9$ followed by
a sequence of digits ($0\dots9$). \\
Examples: $0, 1, 2, 1024$, but not: $01$.
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Float} \\
Declaration: $float$ \\
Represents a \term{binary64} \acronym{ieee}-754 floating point number.
For possible values, please refer to the standard or to the table in
\url{https://en.wikipedia.org/wiki/IEEE\_754#Basic\_and\_interchange\_formats}.\\
Constructors: any integer followed by a dot and a sequence of digits,
              optionally followed by $e$ followed by an integer.
              \comment{The exponential form is not yet available.} \\
Examples: $-1.0, 0.0, 1.0, 3.14159, 1.797693e308$ 
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Time} \\
Declaration: $time$, $date$ \\
Values:  \acronym{utc} 1677-09-21T00:12:44 --
         \acronym{utc} 2262-04-11T23:47:16 \\
Precision: nanosecond. \\
Note, however, that range and precision depend on server configuration.
With less precision, a greater range can be reached.
Please refer to the database configuration guide. \\
Timezone: \acronym{utc} \\
Constructor: any integer or any string following \acronym{iso}-8601 
or any string following a locally defined time format. \\
Examples:\\
1535284617906179393, \\
'1940-12-21', \\
'1904-06-16T11:43:10', \\
'2011-11-11T11:11:11.123456789'
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Bool} \\
Declaration: $bool$ \\
Values: $true$, $false$
\comment{Currently, Bool cannot be stored in the database.
The future solution won't be to store single Booleans, anyway,
but bit patterns.}
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Text} \\
Declaration: $text$ \\
Values: \acronym{utf}-8 string with up to 255 bytes\\
Constructor: string enclosed by ' \\
Examples:\\
'hello world',\\
\begin{CJK}{UTF8}{gbsn}
'鎮州臨濟慧照禪師語錄序。' 
\end{CJK} \\
\comment{An important detail is not yet handled:
text that \emph{contains} the character '.
This is important for recursive \sql, \eg\ \\
\term{exec metaquery('select * from myedge 
       where a = $\backslash$'some text$\backslash$'')}}
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Longtext} \\
Declaration: text \\
Values: \acronym{utf}-8 string with up to 4096 bytes\\
\comment{Longtext is not yet available.}
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Blob} \\
\comment{Blob is nice to have, but there are currently
no concrete plans to add such a datatype.}
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{NULL} \\
\acronym{null} is a special value available for all types.
It signals the absence of a value for the requested field.
For instance, when a vertex was inserted with a subset
of its attributes, a query on that vertex including
those attributes in the \term{select} clause
will produce \acronym{null} as value in the
columns related to these attributes.
Note that it is not possible to compare any value to \acronym{null}
using $= or \neq$. The special operator \keyword{is} must
be used for that purpose, \eg\
\keyword{where} \identifier{name} \keyword{is not null}.
\end{minipage}

\subsection{Dynamic Types}
Dynamic types are not used in \sql\ statements,
but rather describe the return values of \sql\
statements. As such, they live in the context
of a host language (C, Python, Lua, \etc).
Their concrete implementation, therefore,
depends on that language and any language
functioning as either client or server-side host
needs to implement these types.
For more information on concrete implementations
of dynamic types, please refer to the
host language \acronym{api} specifications.

\begin{minipage}{\textwidth}
\textbf{Status}\\
Values: \acronym{ok}, \acronym{nok}\\
In the case of error (\acronym{nok}), \nowdb\ provides:
\begin{itemize}
\item an error code
\item a detailed error message
\end{itemize}
Error codes together with a brief description
of their meaning can be found in \ref{chpt_errors}.
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Report}\\
Reports consist of up to three values:
\begin{itemize}
\item number of affected rows
(returned by all \acronym{dml} and \acronym{dll} statements)
\item number of errors
(returned only by \acronym{dll} statements)
\item running time
(returned by most \acronym{dml} and \acronym{dll} statements)
\end{itemize}
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Row}\\
A row is the result of a projection;
it consists of an array of values
with type information called \term{fields}.
In the host language, one would access a field
typically by an expression of the form:
$row.field(i);$
which would return a tuple $(value,type)$.

A row result consists of one or many rows.
The host language shall provide means
to iterate over rows.
\end{minipage}

\begin{minipage}{\textwidth}
\textbf{Cursor}\\
A cursor is an iterable collection of rows.
The iteration directive is \term{fetch}.
Each fetch may return one or many rows.
A cursor is a server-side resource
and shall be closed using the directive \term{close}.
\end{minipage}

\section{Expressions}
Some \sql\ clauses, like \term{select}, 
\term{where} or \term{insert},
allow the use of \term{expressions}.
Which expressions are valid 
in a specific context varies between
clauses.

The simplest expression,
which is available in all clauses
(that allow expressions),
is a constant value,
\eg\ $true, +4, 3.14159,$ `hello world', \etc\
In some clauses, such as \term{select},
field names are also valid expressions.

Expressions are evaluated when the
\sql\ statement is processed.
The result of the evaluation is
a value with a static type.
In the case of a constant value,
the result is just that constant value.
In the case of a field name,
the result is the value stored in
the corresponding field in the
row that is currently processed.

Expressions may be combined
with operators or functions
to form more complex expressions.
If $\circ$ is a binary operator
and $a$ and $b$ are valid expressions,
then
$a \circ b$
is also a valid expression.
In consequence, $a \circ b$ can
again be used with an operator
to form an even more complex
expression:
$a \circ b \circ c$.
Examples of binary operators are
$+, -, /$ and $\times$.

To enforce a specific order of
evaluation, parentheses may be used.
So, if $a$ is a valid expression,
$(a)$ is as well, for instance
$(a+b)/2$
is a valid expression.

Besides binary operators, there are also
unary operators, \ie\ operators that
take only one operand. Those operators
are usually prefixes. An example of
a unary operator is $not$:
if $a$ is a valid expression,
so is $not~a$.

Expressions may also contain
functions. Functions are very
similar to operators, but differ
in syntax. Functions have the
form

\identifier{function}(
\identifier{argument},
\identifier{argument},
$\dots$),

where \term{function} is the name
of the function and the \term{arguments}
are again expressions.
If $\Phi$ is a function
that takes one argument and
$a$ is a valid expression,
then $\Phi(a)$ is a valid expression too.
An example of a function is $log$,
which computes the natural logarithm
for a number $a$. Valid expressions,
hence, are $log(a)$, $log(a)/log(2)$ and
$log(2.718281828)$.

The validity of an expression depends
also on types. Operators and functions
expect arguments of certain types.
Some operators and functions are limited
to a specific type or type family,
\eg\ to numeric types,
to Booleans or to text; when applied
to values of types they do not expect,
the expression evaluates to a type error
and the related \sql\ statement fails.

In some cases, arguments are \term{promoted}
to other types. Binary operators typically
expect both operands to be of the same type.
If one differs from the other, one of them
may be promoted.

Promotion for numerical types follows 
the precedence:
$\term{float} > \term{int} > \term{uint}$.
In the following example, we try to
add a \term{float} and an \term{int}:
$3.14159 + 1$. In this case, the \term{int}
is promoted to a \term{float} and the
result is a \term{float},
namely $4.14159$.

In general, if at least one of the
operands or arguments is a \term{float},
all values are promoted to \term{float}.
Likewise, if at least one of the operands
is an \term{int} (but none of them is a \term{float}),
then all others are promoted to \term{int}.
Non-numerical types (like \term{bool} and \term{text}),
however, are never promoted to another type.

\subsection{Operators and Functions}
\subsubsection{Arithmetic}
Arithmetic operators and functions
accept only numerical values.
If not mentioned otherwise,
promotion follows precedence as described above.
The basic arithmetic operators are
\begin{verbatim}
+, -, *, /, %
\end{verbatim}
The first three of them have the obvious meaning.
\comment{There is an annoying ambiguity in the
tokeniser affecting $+$ and $-$. The parser
confuses \tech{+b} in \tech{a+b} with the pattern for
integers. Workaround is to either introduce
a blank before \tech{b}: \tech{a+ b} or to put parentheses
around it: \tech{a+(b)}.}

Division (/), however, is different in that it
has different meaning for different numerical types.
For \term{float} values it performs floating point
division. For integral values (type \term{int} and
\term{uint}), however, it computes the quotient
of the Euclidean division, \eg\ $5/2$ is $2$.
However, $5.0/2$ is $2.5$, because $2$ is promoted
to \term{float} according to the precedence rule.

The fifth operator (\%) is the remainder of
the Euclidean division.
It operates only on integral values and results
in a type error if applied to \term{floats}.

It should be noted that this is not the modulo
operator ($mod$) with which the remainder is
often confused. People often expect the 
remainder to always return a non-negative result.
But that is not the case. The remainder is the
unique number $r$ for which

$a = qb + r, r < b$,

where $q$ is the quotient $a/b$.

In consequence, if $a$ is negative and $b$
is positive, then the quotient and the 
remainder are negative, \eg\
$-7 = -2\times 3 -1$ for $a=-7$ and $b=3$.

If $a$ is positive and $b$ is negative, then
the quotient is negative but the remainder
is positive, \eg\
$7 = -2\times -3 + 1$.

If both, $a$ and $b$, are negative,
then the quotient is positive and 
the remainder is negative, \eg\
$-7 = 2\times -3 -1$.

\paragraph{Power}
The power operator is $^{\wedge}$.
It always promotes all its arguments to \term{float}
and always returns a \term{float}.

Please notice that there is no \term{root} operator.
Instead, the root is computed by raising to the power
of a fraction, \eg:

$\sqrt[2]{n} = n^{\wedge}{(1/2)}$,\\
$\sqrt[3]{n} = n^{\wedge}{(1/3)}$,\\
$\sqrt[4]{n} = n^{\wedge}{(1/4)}$,\\
$\dots$

\paragraph{Log}
As mentioned, the function $log$
implements the natural logarithm.
The function promotes its argument to \term{float}
and always returns a \term{float}.

The natural logarithm finds $x$ in the equation
$n=e^{x}$ for a given $n$, where $e$ is the
\term{Euler-Napier} constant, which is
$\approx 2.718281828$.

Logarithms to any base other than $e$
can be easily found by the formula
$\log(n)/\log(b)$, where $b$ is the
desired base. The binary logarithm
of $n$, for instance, is
$\log(n)/\log(2)$.

\paragraph{Absolute Value}
The function $abs$ computes the
absolute value of its argument, \eg:
$abs(-1)$ is 1.
The function accepts any numerical type
and returns a value of the same type as the argument.

\paragraph{Rounding}
The rounding functions are $round$, $ceil$ and $floor$.
All of them promote their argument to \term{float}
and always return a \term{float} value.

$round(n)$ returns the integer closest to $n$,
which may be $n$ itself; if the next greater and
next smaller integer are equally far away,
\ie\ if the digital part of $n$ is $.5$,
the result is the next greater integer.

$ceil(n)$ returns $n$ if $n$ is an integer or,
otherwise, the next integer;
\ie\ it always rounds up, \eg: $ceil(1.1)$ is 2.

$floor(n)$ returns either $n$ if $n$ is an integer
or, otherwise, the previous integer, \ie\ it always rounds down;
\eg: $floor(1.9)$ is 1.

\subsubsection{Conversions}
\nowdb\ provides explicit conversion functions
between numerical types. The conversion functions
are   
$tofloat, toint$ and $touint$.
If conversion is applied according to precedence,
the respective function has the obvious result,
\ie\ converting upwards preserves the full value
if possible.

$tofloat(1)$, for instance, is $1.0$ and
$toint(1)$ is $1$.
$toint(18446744073709551615)$, however, is $-1$.
This is because $18446744073709551615$ is
$2^{64}-1$ and, hence, out of range of \term{int}.
Similar effects happen with applications of
$tofloat$ on values out of range.
Please refer to the 
\acronym{ieee}-754 specification for details.

Converting against precedence,
\ie\ converting downwards,
does not always preserve the value.
When converting a \term{float}
value to an integral type, the decimal part
is lost, \eg\ $toint(3.14159)$ is 3.

Converting negative numbers to \term{uint},
does not preserve value, but the bit pattern.
$touint(-1)$, for instance, is
$18446744073709551615$.

There is also a way to create a textual
representation of a number, namely $totext$.
This function always produces a textual
representation of the constructor for that
number expression,
\eg\ $totext(1.0)$ is '1.0',
$totext(1)$ is '1' and
$totext(+1)$ is '+1'.
\comment{totext is not yet available.
Further missing are the inverse functions
parsefloat, parseint, parseuint, parsebool.}

\subsubsection{Boolean}
Boolean operators and functions
are those resulting in a Boolean value.
They are, hence, not defined by the type
of their arguments, but by their result type.

There are different categories of Boolean
operators (or functions):
boolean operators in the strict sense,
comparisons and special Operators.

\paragraph{Boolean Operators in the Strict Sense}
are \keyword{and}, \keyword{or} and \keyword{not}.
What makes them strict Boolean operators is
that their operands must be Boolean values.
Boolean operators can be used in all clauses
where expressions can be used.
But they are especially important for the
\term{where} clause and will be discussed
in more detail there (please refer to section
\ref{subsec_where}).

\paragraph{Comparisons}
compare values and return
a Boolean value according to the comparison.
Some comparisons are restricted in terms
of the types of their arguments;
others are unlimited. All comparisons, however,
must always compare values of the same type.
Comparing incompatible values leads to a type error.
For numeric types, the same promotion rules
as for arithmetic operators apply.

The main comparison operators are
\begin{verbatim}
= < > <= >= != <>
\end{verbatim}
with the obvious meaning for
the first five operators;
The last two operators
are synonym and both implement
the mathematical operator $\neq$.

The operators $=$ and $\neq$ can be used
with any type. $=$ evaluates to $true$
if the values are equal, \ie\
their type is equal (or compatible
via promotion) and their value
is equal. For instance,
$1 = 1$ is $true$;
$1 = 1.0$, after promotion to \term{float},
is also true; but
$1 =$ `1' results in a type error.

Furthermore, `hello' $=$ `hello'
is $true$, while `Hello' $=$ `hello'
is $false$.

Finally, $true = true$ and
$false = false$ is $true$, while
$true = false$ and $false = true$ are
$false$.

The operator $\neq$ is $true$,
if the operands are not equal.
$\neq$, hence, is the negation
of $=$. The expression $a\neq b$ is equivalent to
$not (a=b)$

The \term{inequality} operators
$<,>,\le$ and $\ge$ can only be applied
to numerical types (and result in a
type error otherwise).

All comparison operators return $false$
when applied on the special value \acronym{null}.
That is \acronym{null} is neither equal nor
not equal to any other value. It is also
not greater or less than any other value.
It is incomparable. 

\paragraph{Special Operators}
are similar to comparison operators
but with peculiar operands.
Special operators are
\keyword{is},
\keyword{between},
\keyword{in},
\keyword{having},
\keyword{exists},
\keyword{any} and
\keyword{all}.

\comment{
\keyword{between},
\keyword{having}, 
\keyword{exists},
\keyword{any} and \keyword{all}
are not yet available.}

The operator \keyword{is} must be used
to compare with the special value
\acronym{null}, \eg\ 1 \keyword{is null}
(which is $false$) 
or 1 \keyword{is not null}
(which is $true$).
The expression
$a$ \keyword{is not null} is
equivalent to
\keyword{not}($a$ \keyword{is null}).

The operator \keyword{between} tests
whether a value is in a range.
Its first operand is an expression,
while its second operand is a range,
for instance
1 \keyword{between} $[1,2]$,
which evaluates to $true$,
since \keyword{between} in this form is
\term{inclusive}.

\keyword{between} has a special syntax
for the brackets to indicate
ex- or inclusiveness. The following
form would exclude the first:
1 \keyword{between} $]1,2]$,
which would evaluate to $false$
because, in this form, the first
element is excluded from the range.
Correspondingly,
\keyword{between} $[1,2[$
would exclude the last element from the range
and
\keyword{between} $]1,2[$
would exclude both.

\keyword{between} is especially interesting
with time periods. We could, for instance,
select all data of the first three months
of year 2010 with the expression:
\keyword{stamp} \keyword{between}
[`2010-01-01', `2010-04-01'[.

The operator \keyword{in} tests
whether a value is in a set.
Its first operand is an expression,
while its second operand is a list
of expressions enclosed by parentheses,
\eg\ 1 \keyword{in} $(1,2,3)$,
which is $true$, or
1 \keyword{in} $(2,3,4)$,
which is $false$.

In a \term{where} clause
the second operator of the \keyword{in} operator
may be a \acronym{dql} statement, \eg\
1 \keyword{in}
(\keyword{select} 1 \keyword{from} \identifier{sales}).
\acronym{dql} statements may also be used
for the second operand of the the operators
\keyword{exists}, \keyword{any} and \keyword{all}.

\keyword{exists} tests whether a set contains
data (\ie\ is not the empty set).
The basic form is \keyword{exists} $(1,2,3)$,
which is $true$.
\keyword{exists} is especially useful with subqueries.

\subsubsection{Conditionals}
\paragraph{The Case Expression}
Conditionals can be constructed by means
of the \keyword{case} expression.
The general syntax is:

\keyword{case}\\
\hspace*{1cm}\keyword{when} \textit{condition$_1$} 
\keyword{then} \textit{value$_1$} \\
\hspace*{1cm}\keyword{when} \textit{condition$_2$} 
\keyword{then} \textit{value$_2$} \\
\hspace*{1cm} $\dots$\\
\hspace*{1cm}\keyword{else} \textit{value$_n$} \\
\keyword{end}

where the conditions are boolean expressions
and the values are any expressions.
For instance:

\keyword{case}\\
\hspace*{1cm}\keyword{when} \identifier{price} $>$ 100.0
\keyword{then} 'expensive' \\
\hspace*{1cm}\keyword{when} \identifier{price} $>$ 50.0
\keyword{then} 'not cheap' \\
\hspace*{1cm}\keyword{when} \identifier{price} $>$ 20.0
\keyword{then} 'considerable' \\
\hspace*{1cm}\keyword{when} \identifier{price} $>$ 5.0
\keyword{then} 'not for free' \\
\hspace*{1cm}\keyword{else} 'acceptable' \\
\keyword{end}

Note that the whole construct enclosed by
the keywords \keyword{case} and \keyword{end}
is an expression. \keyword{when}, \keyword{then}
and \keyword{else} alone do not form expressions;
they can only be used within a \keyword{case}.

A \keyword{case} expression consists of at least
one \keyword{when}/\keyword{then} construct.
Without such a construct, the \keyword{case}
is invalid.

Likewise, a \keyword{case} must contain at most
one \keyword{else}
and that \keyword{else}
must be placed behind all \keyword{when} constructs.
With more than one \keyword{else}
or with an \keyword{else} that is followed
by one or more \keyword{when} constructs,
the \keyword{case} is invalid.

The \keyword{when} constructs are evaluated
in the order in which they appear in the \keyword{case} expression.
The \keyword{case}, thus, evaluates
to the \term{value} branch of the first \keyword{when}
whose condition branch evaluates to \keyword{true}.

If none of the \keyword{when} conditions evaluates to \keyword{true},
the \keyword{case} expression evaluates
to the \keyword{else} \term{value}.
If there is no \keyword{else},
the \keyword{case} expression
evaluates to \keyword{null}.

The \keyword{when} and \keyword{else} values
may be of different types.
For instance:

\keyword{case}\\
\hspace*{1cm}\keyword{when} \identifier{category} $=$ 1
\keyword{then} 'true' \\
\hspace*{1cm}\keyword{when} \identifier{category} $=$ 2
\keyword{then} 1 \\
\hspace*{1cm}\keyword{when} \identifier{category} $=$ 3
\keyword{then} true \\
\hspace*{1cm}\keyword{else} \keyword{null} \\
\keyword{end}

However, care must be taken when using this feature.
Often the context where the \keyword{case} expression
appears requires a certain type, \eg: 

\keyword{select} 1 +
\keyword{case}\\
\hspace*{2.5cm}\keyword{when} \identifier{category} \keyword{is null}
\keyword{then} 0 \\
\hspace*{2.5cm}\keyword{else} \identifier{price} + category * 0.1 \\
\hspace*{2cm}\keyword{end}

This context expects a numerical value.
Evaluation will fail with a non-numerical value
like in the following case

\keyword{select} 1 +
\keyword{case}\\
\hspace*{2.5cm}\keyword{when} \identifier{category} \keyword{is null}
\keyword{then} \keyword{false} \\
\hspace*{2.5cm}\keyword{else} \identifier{price} + category * 0.1 \\
\hspace*{2cm}\keyword{end}

This is of importance in the \keyword{where} clause.
When a \keyword{case} expression is used in a \keyword{where}
like this:

\keyword{where} \keyword{case} $\dots$ \keyword{end}

\ie\ the whole \keyword{where} evaluates to the result
of the \keyword{case} expression, the \keyword{case}
must evaluate to a boolean. Otherwise the effect of
the \keyword{where} clause is undefined.

\paragraph{Coalesce}
\identifier{Coalesce} is a function that accepts
an unspecified number arguments.
\identifier{Coalesce} evaluates to
the first argument that itself
does not evaluate to \keyword{not null}.
If none of the arguments is \keyword{not null},
\identifier{coalesce} evaluates to \keyword{null}.
Example:

\identifier{coalesce}(\identifier{category}, 99)

If the field \identifier{category} is \keyword{null},
\identifier{coalesce} evaluates to 99;
otherwise, it evaluates to the current
value of \identifier{category}.

Since \identifier{coalesce} accepts
an undetermined number of argument,
the following expression is legal:

\identifier{coalesce}(\identifier{species},
                      \identifier{genus},
                      \identifier{family},
                      \identifier{order},
                      \identifier{class},
                      \identifier{phylum},
                      \identifier{kingdom},
                      \identifier{domain},
                      'life')

The following expression evaluates to \keyword{null},
whenever \identifier{category} evaluates to \keyword{null}
(and is as such pointless):

\identifier{coalesce}(\identifier{category}, \keyword{null})

By contrast, this statement always evaluates to 99:

\identifier{coalesce}(\keyword{null}, 99)

The arguments may be of different types.
But, again, care must be taken when using this feature.

\subsubsection{Bitwise Operators}
$\ll, \gg, \&, |,\sim$, xor, bit

\comment{Not yet available.
Bitwise operators, however, are very interesting
to store bools. It is not very efficient to
store single booleans in the database.
It is interesting, however, to store
bitmaps; but the database needs
to provide support for working with bitmaps.}

\subsubsection{Time}
\paragraph{Time Component Functions}
Time component functions return a part of the time,
such as the year, the month, the day of the month,
\etc\ as \keyword{int} according to the European calendar.
Example:

\keyword{select} \identifier{year}(\keyword{stamp})
\keyword{from} \identifier{sales}

\identifier{year} returns the year, \eg\ 2018.

\identifier{month}
returns the month starting from January as 1.

\identifier{mday}
returns the day of the month (1-31).

\identifier{wday}
returns the day of the week with
Monday = 1, Tuesday = 2, $\dots$, Saturday = 6 and
Sunday = 0.

\identifier{yday}
returns the day of the year.

\identifier{hour}
returns the hour of the day from $0\dots 23$.

\identifier{minute}
returns the minute of the hour from $0\dots 59$.

\identifier{second}
returns the second of the minute,
which is almost always between $0\dots 59$.
In case of leap seconds, however, 60 may be returned.

\identifier{milli}
returns the milliseconds within the second.

\identifier{micro}
returns the microseconds within the second.

\identifier{nano} 
returns the nanoseconds within the second.

\paragraph{Points in Time}
The following functions return specific points in time.
They take no argument and return a \keyword{time} value.
Example:

\keyword{select} \identifier{now}()
\keyword{from} \identifier{sales}

\identifier{now}
returns the current system time.

\identifier{dawn, dusk}
return the earliest (\identifier{dawn}) and
the latest (\identifier{dusk}) point in time
that can be represented.

\identifier{epoch}
returns the system's epoch
(usually `1970-01-01T00:00:00').

\paragraph{Time Formatting}
\comment{Not yet available}

\subsubsection{Geospatial}
\comment{
Not yet available.
Planned are:
geohashing,
distance calculation,
bounding boxes,
box is in another box,
boxes share area,
boxes touch each other,
etc.
}

\subsubsection{Text}
\comment{Not yet available}

\subsection{Aggregates}\label{sec_agg}
Aggregates are functions (and, hence, may be part
of expressions) with very special behaviour and
very special restrictions concerning their usage
context.
While all functions (and operators) we have looked at
so far, are applied to \emph{single} values,
aggregates are applied
to \emph{sets} of values. They produce,
as their name suggests, an aggregation of the
values in the set like the number of elements
in the set (\identifier{count}),
the sum of all the values in the set
(\identifier{sum}) or the average (\identifier{avg})
or the median (\identifier{median}).
They, hence, behave like \term{map} and
\term{reduce} operators.

The set of values to which an aggregate is applied
depends on its usage. Aggregates may be applied
to all data in the result set or to all data
in a \term{group} (please refer to section \ref{sec_group}
for details).

The aggregate arguments are expressions.
There may be restrictions
on the type of expression that can be used
with a particular aggregate.
In general, however, aggregates may
be applied to any kind of expression.
For instance,
\identifier{sum}(1) is equivalent to
\identifier{count}($\ast$) and
\identifier{avg}(\keyword{weight}$^{\wedge}2$) would compute
the average of the squares of the values
of field \keyword{weight}.

Aggregates can also be part of expressions.
The formula 
\identifier{sum}(\keyword{weight})
/ \identifier{count}($\ast$),
for instance, would be equivalent to
\identifier{avg}(\keyword{weight}).

\subsubsection{count}
The function counts the values in a set.
It takes one argument, which may be any expression,
but few expressions really make sense with \identifier{count}.

The function is applied either to the row (\identifier{count}($\ast$))
or to a part of it (\identifier{count}(\identifier{field}))
or to anything else (\identifier{count}(1)).
However, these expressions are all equivalent.
 
When applied to a field, \identifier{count} is usually combined with
\keyword{distinct} (\comment{which is not yet available}),
otherwise the result would be the same as applying it to the row.
Common examples are therefore:

\keyword{select} \identifier{count}($\ast$) \keyword{from} \identifier{sales}

and

\keyword{select} \identifier{count}(\keyword{distinct} \keyword{edge})
\keyword{from} \identifier{sales}

The return type is always \keyword{uint}.

\subsubsection{sum}
The function takes one argument and
produces the sum of the values
to which its argument evaluates over the result set,
\eg\ the values in a field.

The argument must be numeric.
The return type depends on the type of the input field.

Example:

\keyword{select} \identifier{sum}(\keyword{weight}) \keyword{from} \identifier{sales}

produces the sum of the values in the weight fields
for the whole table \identifier{sales}.

\subsubsection{max and min}
The functions take one argument.
Function \term{max} produces the greatest value in the result set
and function \term{min} produces the smallest value in the result set.

The arguments must be numeric.
The return type depends on the type of the input field.
Example:

\keyword{select} \identifier{max}(\keyword{weight}),
                 \identifier{min}(\keyword{weight})
\keyword{from} \identifier{sales}

\subsubsection{spread}
The function takes one argument.
It produces the difference $max - min$,
where $max$ is the greatest value in the result set
and $min$ is the smallest value in the result set.

The argument must be numeric.
The return type depends on the type of the input field.

Example:

\keyword{select} \identifier{spread}(\keyword{weight})
\keyword{from} \identifier{sales}

\subsubsection{avg}
The Function takes one argument.
It produces the arithmetic mean of the values
of this field in the result set, \ie

\[
\left(\sum{x}\right)/n,
\]

where $x$ represents the
field values in the result set and $n$
is the number of rows (\ie\ \identifier{count}($\ast$)).

The argument must be numeric.
The return type is \keyword{float}.

Example:

\keyword{select} \identifier{avg}(\keyword{weight})
\keyword{from} \identifier{sales}

\subsubsection{median}
The Function takes one argument.
It finds the central point (or, in case
the number of rows is even, the average
of the two central points), when the values are ordered.

The argument must be numeric.
The return type is \keyword{float}.

Example:

\keyword{select} \identifier{median}(\keyword{weight})
\keyword{from} \identifier{sales}

\comment{
No precaution is currently taken for the case
that the result set outgrows available memory.
In that case the query will fail (and probably the queries
in other sessions too).
}

\subsubsection{mode}
The Function takes one argument.
It finds the most frequent value in the result set.

The argument may be of any type.
The return type depends on the type of the input field.

\keyword{select} \identifier{mode}(\keyword{weight})
\keyword{from} \identifier{sales}

\comment{
Not yet available
}

\subsubsection{stddev}
The Function takes one argument.
It finds the standard deviation according to the formula:

\[
\sqrt{\frac{\sum_{i=1}^{N}{(x_i - \overline{x})^2}}{N-1}},
\]

where $N$ is the number of rows in the result set,
$x_i$ is the $i$th element and $\overline{x}$ is
the arithmetic mean (\ie\ \identifier{avg}).

The argument must be numeric.
The return type is \keyword{float}.

\keyword{select} \identifier{stddev}(\keyword{weight})
\keyword{from} \identifier{sales}

\comment{
Note that there is not much optimisation done in aggregates.
For instance, \term{median} and \term{stddev} create a
collection of all values, but each one creates its own collection.
That is, the values are collected twice.
}

\ignore{
\subsubsection{integral}
The Function takes two arguments.
It computes the area under the curve,
where the first argument represents
the values on the $x$-axis and
the second represents the values
on the $y$-axis.

The first argument can be any type;
the second argument must be numeric.
The return type is \keyword{float}

Example:

\keyword{select} \identifier{integral}(
\keyword{stamp}, \keyword{weight})
\keyword{from} \identifier{sales}
}

\comment{
Interesting would be \term{earliest} and \term{latest}
to find the earliest and latest timestamp;
this would be used with \keyword{having}, \eg:
\keyword{having} \identifier{latest}(\keyword{stamp})
}

\section{Data Definition}
\comment{Syntax diagrams will be provided in another document}

\subsection{Schema}
The keywords
\term{schema}, \term{database} and \term{scope}
are interchangeable.

\subsubsection{CREATE}
The \term{create schema} statement
creates an empty database physically on disk.
It has the following form:

\keyword{create schema} \identifier{mydb}

This would create all objects necessary
to manage that database.

The following forms are equivalent:

\keyword{create database} \identifier{mydb}\\
\keyword{create scope} \identifier{mydb}

All \keyword{create} clauses can be combined
with the clause \keyword{if not exists}, \eg:

\keyword{create schema} \identifier{mydb} \keyword{if not exists}

The \keyword{if not exists}-clause
suppresses the `duplicate key' error
in case the schema
already exists.
It is a convenient way to avoid
that a \sql\ script is abandoned
in such a situation.

\subsubsection{DROP}
The \term{drop schema} statement
removes a database physically from disk.
It has one of the following forms,
which are all equivalent:

\keyword{drop schema} \identifier{mydb}\\
\keyword{drop database} \identifier{mydb}\\
\keyword{drop scope} \identifier{mydb}

The statement removes all objects and data
belonging to the database `mydb' from disk.

All \keyword{drop} clauses can be combined
with the clause \keyword{if exists}, \eg:

\keyword{drop schema} \identifier{mydb} \keyword{if exists}

The \keyword{if exists}-clause
suppresses the `key not found' error
in case the schema
does not exist.
It is a convenient way to avoid
that a \sql\ script is abandoned
in such a situation.

% \subsubsection{ALTER}

\subsection{Table}
\subsubsection{CREATE}
The \term{create table} statement
creates a new storage entity for edges
physically on disk.

The simplest form is:

\keyword{create table} \identifier{mytable}

The keyword table may be decorated
with a sizing option:

\keyword{create big table} \identifier{mytable}

Valid sizing keywords are:
\keyword{tiny, small, medium, big, large, huge}.

Sizing keywords affect the allocation units
of disk space. The concrete meaning is not
part of this specification and may change
in the future.

It is also possible to add options to
to a \term{create table} statement.
Options have the general form

\term{\keyword{set} option = value, option = value}.

Valid options and values are listed in the following table:

\bgroup
\renewcommand{\arraystretch}{1.3}
\begin{center}
\begin{tabular}{||c||c||c||c||}\hline
Option & Values & Meaning & Default \\\hline\hline
\keyword{stress} & \keyword{moderate} & Low ingestion volume with occasional peaks & X \\\cline{2-4}
                 & \keyword{constant} & Constant ingestion of high volume          &   \\\cline{2-4}
                 & \keyword{insane} & Constant ingestion of very high volume       &   \\\hline\hline
\keyword{disk} & \keyword{hdd}  & Disk space is allocated in large chunks          & X \\\cline{2-4}
               & \keyword{ssd}  & Disk space is allocated in small chunks          &   \\\cline{2-4}
               & \keyword{raid} & Currently, no effect                             &   \\\hline\hline
\keyword{compression} & 'zstd'  & zstd is used for compression                     & X \\\cline{2-4}
                      & 'lz4'   & lz4 is used for compression (\comment{not available}) &   \\\cline{2-4}
                      & ''      & Data in this table are not compressed at all     &   \\\cline{1-4}
\end{tabular}
\end{center}
\egroup

The option \keyword{stress} affects the number of threads
allocated to perform ingestion tasks
like compression, sorting and indexing.
How many threads are allocated
is not part of this specification
and may vary between platforms.

The user may decide on the compression algorithm to use.
The standard compression algorithm is \term{zstd},
which is fast, but has also very good compression ratio.
It is recommended to use \term{zstd} in most cases.
\term{lz4} (\comment{not yet available}) is faster than \term{zstd},
in particular on decompression,
but has a weaker compression ratio.
Finally, no compression at all (empty string)
makes sense on small tables
that are known never to grow beyond some megabyte in size
(or beyond some million edges).

An example of a \term{create table} statement with options is

\keyword{create table} \identifier{mytable}
\keyword{set} \keyword{stress} = \keyword{constant},
              \keyword{compression} = 'zstd'

\subsubsection{DROP}
The \term{drop table} statement removes
an existing storage entity for edges
physically from disk.
It has the form:

\keyword{drop table} \identifier{mytable}

% \subsubsection{ALTER}

\subsection{Type}
\term{Types} are user-defined types
stored as vertices in the database.
The syntax resembles very much
the \term{create table} syntax
in traditional \sql:

\begin{minipage}{\textwidth}
\keyword{create type} \identifier{product} \{ \\
\hspace*{1cm}\identifier{prod\_key} \keyword{uint} \keyword{primary key}, \\
\hspace*{1cm}\identifier{prod\_desc} \keyword{text}, \\
\hspace*{1cm}\identifier{prod\_price} \keyword{float} \\
\}
\end{minipage}

This creates a type called \term{product}
with three attributes:
\term{prod\_key}, \term{prod\_desc} and \term{prod\_price}.

There is no limit on the number of attributes
a type may have. Indeed, vertices with hundreds
of attributes are not uncommon.

Attributes may have any static type with one exception:
Each type needs a unique primary key and the field
that is primary key must be either
\keyword{uint} or \keyword{text}.

The order in which attributes are declared
determines the \term{canonical} order for this type.
The canonical order plays a role for the \term{insert}
statement.

\subsubsection{DROP}
The \term{drop type} statement removes a type
from the database. \comment{
At the moment, drop type removes only the type definition,
not the corresponding data;
in the future, that will certainly change.
}
It has the form:

\keyword{drop type} \identifier{product}

\subsection{Edge}
\subsubsection{CREATE}
The \term{create edge} statement defines the layout
of a specific edge type in the database.
Example:

\keyword{create edge} \identifier{buys} \{ \\
\hspace*{1cm} \keyword{origin} \identifier{client} \keyword{as} \identifier{client}, \\
\hspace*{1cm} \keyword{destin} \identifier{product} \keyword{as} \identifier{product}, \\
\hspace*{1cm} \keyword{label} \keyword{text}, \\
\hspace*{1cm} \keyword{weight} \keyword{int} \keyword{as} \identifier{quantity}, \\
\hspace*{1cm} \keyword{weight2} \keyword{float} \keyword{as} \identifier{paid} \\
\}

Edges have seven fields (in canonical order):
\keyword{edge},
\keyword{origin}, \keyword{destin},
\keyword{label}, \keyword{timestamp},
\keyword{weight} and \keyword{weight2}.

The type of the field `edge' is predefined.
It is always a string and corresponds to the
name of that edge (\eg\ `buys').
The reason that it exists at all
is that edges of different types can be stored
in the same table.
This makes especially sense for groups of edges
with few instances or for groups of edges
that are often read together.
Think for instance of \term{follow} and \term{unfollow}
in a social media application.
We might want to read \term{follow} and \term{unfollow}
events together ordered by timestamp to determine
what the current state is.

Likewise is the type of the timestamp predefined
and cannot be changed.

All other types can be defined.
The types of \keyword{origin} and \keyword{destin}
are usually vertex \keyword{type}s, since they refer
to vertices which are connected by this specific edge.
Stored in the database is the value of the primary key
of the specific type (\ie\ \keyword{uint} for product).

But they also may have static types, namely
\keyword{uint} or \keyword{text}.

The field \keyword{label} as well may be of type
\keyword{uint} or \keyword{text}.

The fields \keyword{weight} and \keyword{weight2}
may have any static type.

Fields that are not mentioned in the edge definition
are invisible and cannot be used.

\comment{
Some aspects of the design are centred around the idea
that it should be possible to insert \textit{ad-hoc}
data, in particular edges,
that were not previously defined in terms of \acronym{ddl}.
More recent design decisions (like the one above)
foreclose this possibility.
This is still an ongoing design process and
some details may change...
}

It is also possible to rename edge fields
according to their real purpose in a concrete
application (\eg\ naming \keyword{weight} \identifier{quantity}).
All fields that may appear in an edge definition
may be renamed in this way.
\comment{Not yet available!}

\subsubsection{DROP}
The \term{drop edge} statement removes an edge definition,
but not the data described by this definition,
from the database.
It has the form:

\keyword{drop edge} \identifier{buys}

\subsection{Index}
\subsubsection{CREATE}
The \term{create index} statement
creates an index physically on disk.
It has the form:

\keyword{create index} \identifier{myidx} \keyword{on} \identifier{mytable}
(\identifier{field1}, \identifier{field2})

The fields (``field1'', ``field2'', \etc)
are edge fields. Any combination of fields
can be used in index definitions.
It is not recommended, however,
to create indices on fields that are defined as \keyword{float}
or \keyword{time} (\eg\ \keyword{timestamp}).

\comment{
There will be the possibility to define indices over ranges
of \keyword{float} fields and periods
of \keyword{time} fields. But that is not yet available.
}

The \keyword{index} keyword can be decorated with a sizing
indication, \eg:

\keyword{create tiny index} \identifier{myidx} \keyword{on} \identifier{mytable}
(\identifier{field1}, \identifier{field2})

The default sizing is \keyword{small}.

It rarely makes sense to create 
\keyword{big}, 
\keyword{large} or 
\keyword{huge} indices.
It actually makes sense,
when the index
has many data points per key.
More details on this can be found in \ref{chpt_sizing}.

\comment {
Vertices have one internal index which is created
when the database is created.
It will be possible in the future to define
indices on vertex attributes.
}

\subsubsection{DROP}
The \term{drop index} statement removes an index physically from disk.
Example:

\keyword{drop index} \identifier{myidx}

\subsection{Procedure}
\subsubsection{CREATE}
The \term{create procedure} statement
creates procedure interface in the database.
It has the form:

\keyword{create procedure} \identifier{mymodule}.\identifier{myfun}(
                           \identifier{param1} \keyword{uint},
                           \identifier{param2} \keyword{text})
                           \keyword{language} \identifier{python}

A procedure may have no parameters.
The definition then simplifies to

\keyword{create procedure} \identifier{mymodule}.\identifier{myfun}()
                           \keyword{language} \identifier{python}

Any number of parameters is allowed and parameters may have
any static type.

Known languages are \identifier{python} and \identifier{lua}.
\comment{Lua is not yet available.}

\subsubsection{DROP}
The \term{drop procedure} statement
drops a procedure interface from the database.
It has the form:

\keyword{drop procedure} \identifier{myfun}

\subsection{Function}
\comment{Not yet available}

\subsection{Period}
\term{Period} is not a \term{first-class citizen}
like types, edges, procedures, \etc\
In particular, periods cannot be created or altered.
They evolve as an effect of inserting edges into
the database. However, periods can be identified
and they can be dropped.

Dropping data according to timestamps is an important
feature in timeseries databases.
Without this feature, databases would grow
to an extent that would make efficient queries difficult
or even impossible. Deleting data by means of the
\term{delete} statement, however, is not efficient for large
amounts of data and in \nowdb\
(but also in other databases), deleting
the data would not solve the problem at all,
because \term{delete} does not physically remove
the data, but just makes them invisible.

Dropping a period, by contrast, removes all data files 
that contain only data belonging to that period and
removing files is a very efficient
operation on most platforms.

The syntax is:

\begin{minipage}{\textwidth}
\keyword{drop period on} \identifier{mytable} \\
\keyword{where timestamp between} $[$'2018-01-01', '2018-04-01'$[$
\end{minipage}

This would drop all data files of table `mytable'
that contain only data between Jan, 1, 2018 (inclusive) and
April, 1, 2018 (exclusive). 

Two remarks are in place. First,
\term{drop period} must have a \term{where} clause
and this clause must contain exactly one condition,
namely \keyword{between} related to the timestamp.

The rationale for this restriction is
to avoid accidentally dropping entire tables
using too complex or incomplete \term{drop} statements.

To illustrate that, the following example 
is legal and it drops all data
before a given date (which is very common
for timeseries databases, that often represent gliding
time windows):

\begin{minipage}{\textwidth}
\keyword{drop period on} \identifier{mytable} \\
\keyword{where timestamp between}
$[$\identifier{dawn}(), '2018-04-01'$[$
\end{minipage}

Second, \term{drop period} does not guarantee
to drop all data that lie in the period in question --
in fact, it does not even guarantee to drop any data at all.
It guarantees, however, to remove all files
that contain \emph{only} data that lie within the period.
In other words, the behaviour is conservative
and prefers dropping fewer data than possible over
dropping too many data.
On the long run, however, with a consistent dropping policy
old data will be removed and the database
won't grow (except when the periods themselves grow).

\section{Data Manipulation}
\subsection{Insert}
The \term{insert} statement inserts one or more rows
to a given table or type.
The basic form is

\keyword{insert into} \identifier{mytable} 
                      (\identifier{myfield1},
                       \identifier{myfield2})
                      (value1, value2)

where `value1' and so on are expressions.
The \term{insert} statement, however,
does not allow for fields as expressions,
since it would not be clear where the fields
should come from.

A more concrete example is

\keyword{insert into} \identifier{product} 
                      (\identifier{prod\_key},
                       \identifier{prod\_desc},
                       \identifier{prod\_price})
                      (100001, 'Spinach', 1.99)

For an edge, this would be:

\begin{minipage}{\textwidth}
\keyword{insert into} \identifier{sales} 
                      (\keyword{edge},
                       \keyword{origin},
                       \keyword{destin},
                       \keyword{timestamp},
                       \keyword{weight},
                       \keyword{weight2})
                      (\\
\hspace*{2.99cm}       'buys', 9000001, 100001,
                       '1929-01-22T08:53:22',
                       3, $3\ast 1.99$)
\end{minipage}

When the list of values is complete,
\ie\ covers all fields in the type or table,
and respects the canonical order,
a shorthand form can be used, \eg:

\keyword{insert into} \identifier{product} 
                      (100001, 'Spinach', 1.99)

Note that, for the shorthand form on edges,
typeable edge fields which were not declared
in the edge definition, must be inserted with
\acronym{null}, \eg:

\begin{minipage}{\textwidth}
\keyword{insert into} \identifier{sales} 
                      ('buys', 9000001, 100001,
                       \acronym{null},
                       '1929-01-22T08:53:22',
                       3, 5.97)
\end{minipage}

where the fourth position is \acronym{null} and represents
the label which was not defined.
\comment{For the time being, please use 0 instead of \acronym{null}.}

It is also possible \comment{(not yet!)} to insert data from
a query, \eg:

\begin{minipage}{\textwidth}
\keyword{insert into} \identifier{sales} ( \\
                      \keyword{edge},
                      \keyword{origin},
                      \keyword{destin},
                      \keyword{timestamp},
                      \keyword{weight},
                      \keyword{weight2}) (\\
\hspace*{0.2cm}\keyword{select} 'buys', \keyword{origin}, 
                         \keyword{destin},
                         \keyword{timestamp},
                         \keyword{weight},
                         \keyword{weight2} \\
\hspace*{0.35cm}\keyword{from} \identifier{another\_table} \\
\hspace*{0.2cm}\keyword{where} $\dots$)
\end{minipage}

Insert (just as data loading) respects data integrity
on vertices. That is, the primary key of the vertex
must be unique for that type. Otherwise, \term{insert}
fails with the error \term{duplicate key}.

Edges, on the other hand, have no primary key.
Several edges that all look the same can be inserted
without limits. For people coming from the relational
world, this may sound strange. However, edges are
timeseries data and in the timeseries world
it is completely acceptable and
even common to insert the same event for the same
point in time. It is not so clear 
what ``same time'' shall mean in the first place.
Typically a point in time in a timeseries application
is not an exact spot (\eg\ that millisecond or that
minute). More often than not events happen in
time frames; how to identify and correlate single events
is not so much database methodology, but data science.

\nowdb\ does also not enforce the relation between
vertex type and edge. That is, one can insert edges
to which no corresponding vertex exist.
The reason is that the life cycles of timeseries data
and master data are often not in sync.
For one, timeseries data may arrive, before the
respective vertices have been inserted into the database
and, even more typical, timeseries data might
outlive their vertices in the database.
A client, for instance, who does not renew his or her
customer card, may be removed from the database;
the timeseries data in the database, however,
are still there.

\subsection{Update}
The \term{update} statement changes the values
of fields in rows in tables or types.
Its general form is

\keyword{update} \identifier{mytable} \\
\hspace*{0.7cm} \keyword{set} field = value,\\
\hspace*{0.7cm} \keyword{set} field = value \\
\hspace*{0.1cm} \keyword{where} $\dots$

For instance:

\keyword{update} \identifier{product} \\
\hspace*{0.7cm} \keyword{set} \identifier{prod\_price} = 1.89 \\
\hspace*{0.1cm}  \keyword{where} \identifier{prod\_key} = 100001

For details on the \term{where} clause,
please refer to the \acronym{dql} section.

\comment{update has still many unsolved issues.
For instance, when changing primary keys
and other indexed fields, we need to delete
that particular row from the index and add it
again with the new value.
That, however, is quite expensive.
It therefore may take still some time
to make update available :-(}

\subsection{Upsert}

\subsection{Delete}
The \term{delete} statement eliminates single
data points from tables or types.
Its general form is

\keyword{delete from} \identifier{mytable} \keyword{where} $\dots$

A more concrete example:

\keyword{delete from} \identifier{product}
\keyword{where} \identifier{prod\_key = 100001}

For details on the \term{where} clause,
please refer to the \acronym{dql} section.

It is worth mentioning that delete
does not physically remove data from disk.
It marks the corresponding rows as deleted,
so they won't be selected by other statements.

\comment{delete still has bugs and is therefore not yet available :-(}

\section{Data Loading}
\subsection{Create}
The \term{create loader} statement creates a user-defined loader.

\comment{Not yet avalailable}

\subsection{Drop}
The \term{drop loader} statement removes a user-defined loader
form the database.

\comment{Not yet avalailable}

\subsection{Load}
The \term{load} statement loads data from an external
data source into the database.
Its general form is

\keyword{load} '/path/to/datafile' \keyword{into} \identifier{mytype\_or\_edge}

The \term{load} statement has optional \term{use} and \term{ignore} clauses
\comment{we also need a clause to add options to a user-defined loader}:

\keyword{use loader} \identifier{myformat}

With this clause, a user-defined loader is applied.
Without this clause the default loader (\acronym{csv})
is applied. That is equivalent to

\keyword{use loader} \identifier{csv}

In the case of a \acronym{csv} loader,
the \keyword{header} option can be used:

\keyword{use header}

or:

\keyword{use csv, header}

which means that the data source has a header and that the loader
will use this header to determine how to load the columns in the data source.
Note that vertices always require a header, while edges
must not use a header. If the data file actually has a header
and edges are to be loaded, the \term{ignore} clause must be used:

\keyword{ignore header}

This will ignore the first line of the \acronym{csv}.

Here is a complete example for the default loader and vertices:

\keyword{load} '/opt/import/client.csv'
\keyword{into} \identifier{client} \keyword{use header}

and for edges:

\keyword{load} '/opt/import/transactions.csv'
\keyword{into} \identifier{sales}

The \term{load} statement returns a report on success
that indicates how many rows have been loaded,
how many rows have failed and how long it took.
Notice that \term{load} does not stop on errors.
Instead, errors are written to a file
with the row number where the error occurred.
This way, the faulty lines can be corrected and
reimported later.

Here is how to indicate an error file:

\keyword{load} '/opt/import/transactions.csv'
\keyword{into} \identifier{sales} \\
\hspace*{0.3cm}\keyword{set errors} $=$ '/opt/import/transactions.err'

If no error file is indicated,
the errors are written to standard error.
This rarely makes sense,
since different sessions can load data concurrently.
Standard error would then contain a mix
of errors of all sessions that tried to load data.

\subsection{Dump}
\comment{Not yet available}

\section{Data Querying}
There is only one type of \acronym{dql} statement.
However, this statement is much more complex
than the statements we have seen so far.

A \acronym{dql} statement consists of at least
a \term{select} clause (also called \term{projection} clause)
and a \term{from} clause, which in itself may contain
a \term{join} clause.
It may additionally contain
a \term{where} clause,
a \term{group} clause and
an \term{order} clause.

\subsection{Select Clause}
The basic form of a \term{select} clause is

\keyword{select} \identifier{expression}, \identifier{expression}, $\dots$

Where any expression is allowed.
If the expression involves a field,
it must be a field of the entity (edge or type)
referenced in the \term{from} clause.
If all fields of that entity are selected,
the statement can be simplified to

\keyword{select} \keyword{$\ast$}

It is also possible to refer explicitly to the data source
(which is identified in the \term{from} clause), \eg:

\keyword{select} \identifier{product}.\identifier{prod\_price}

In the \term{from} clause, we can define aliases for data source
and then refer to the data source by this alias, \eg:

\keyword{select} \identifier{p}.\identifier{prod\_price}

where $p$ is an alias defined in the \term{from} clause.
This is especially useful with joins.

Expressions are, of course, not necessarily fields.
They also may be functions, constants or even complex expressions
composed of fields, constants, functions and operators.
The following are, for instance, valid \term{select} clauses:

\begin{minipage}{\textwidth}
\keyword{select} \identifier{true} \\
\keyword{select} 'X' \\
\keyword{select} 3.14159 \\
\keyword{select} \identifier{sum}(\keyword{weight}) $/$ 42 \\
\keyword{select} \identifier{count}(*), \identifier{sum}(\keyword{weight})
\end{minipage}

The first three clauses may appear pointless.
Why select constant values from the database?
There are, however, very common use cases
for selecting constant values, in particular
in combination with the \keyword{exists} operator,
but also for \acronym{dql} used within an
\term{insert} statement. A concrete example
of the latter already appeared in the section
on \term{insert}, namely:

\keyword{select} 'buys', \keyword{origin},
                         \keyword{destin}, 
                         \keyword{timestamp}, 
                         \keyword{weight},
                         \keyword{weight2}

where a constant expression, namely 'buys',
is combined with a number of fields.

The \term{select} clause may also contain aggregates,
which are applied to partitions of the result set.
On which partition
aggregates are applied, depends 
on the \term{group} clause. If no \term{group} clause
is present, the partition consists of all rows produced
by the \acronym{dql} statement.

The following are valid \term{select} clauses:

\keyword{select} \identifier{count}($\ast$) \\
\keyword{select} \identifier{sum}(\keyword{weight}) \\
\keyword{select} \identifier{sum}(\identifier{log}(\keyword{weight})) \\
\keyword{select} \identifier{avg}((\keyword{weight} $+$
                                   \keyword{weight2}) $/$ 2) \\
\keyword{select} \identifier{stddev}(\keyword{weight})

The freedom of the \term{select} clause
is restricted by other clauses, in particular
the \term{from} clause and the \term{group} clause.
In the \term{select} clause, only
those fields may appear that are actually
part of the entity chosen in the \term{from} clause.
The interdependencies with the \term{group} clause
are more subtle and will be discussed there.

\subsection{From Clause}
The \term{from} clause determines the data source
of the \acronym{dql} statement. The simplest form
of a \term{from} clause is

\keyword{from} \identifier{mytable}

The identifier must refer to a table or a type.
Valid \term{from} clauses are for instance:

\keyword{from} \identifier{sales} \\
\keyword{from} \identifier{product} \\
\keyword{from} \identifier{client}

Here is a first example of a complete \acronym{dql} statement:

\keyword{select} 'buys', \keyword{origin},
                         \keyword{destin}, 
                         \keyword{timestamp}, 
                         \keyword{weight},
                         \keyword{weight2}
\keyword{from} \identifier{sales}

It is possible to define an alias for the data source:

\keyword{from} \identifier{sales} \keyword{as} \identifier{s}

The table \identifier{sales} can now be referred to as ``s''
in all other clauses.
This technique is especially interesting in combination
with joins.

In most \sql\ dialects,
it is common to select data from different
data sources at once, \eg:

\keyword{from} \identifier{product}, \identifier{client}

This form is not supported by \nowdb.
Whenever more than one data source is addressed,
a join has to be used.

\subsection{Join Clause}
A join combines an edge with a vertex.
\comment{
Edges are in fact the way to express
relations between vertices.
There is no other way to combine vertices.
Perhaps, in the future, we need something else.
Many graph databases offer additional links
between vertices, which are not edges.
Usually, these links are used for connections
that are part of the characteristic of the
vertex. One could say that such links express
``o que \'e'', while edges express
``o que est\'a''.
}
The basic form is:

\keyword{join} \identifier{mytype} \keyword{on} \keyword{edgefield}

To make this more concrete:

\keyword{from} \identifier{sales} 
\keyword{join} \identifier{client} \keyword{on} \keyword{origin}

This would produce an \term{inner join} 
between \identifier{sales} and \identifier{client}.
Joins in \nowdb\ are in fact always inner joins.
There are no \term{outer joins}. \comment{Do we need them?}
In consequence, there is no difference between
\term{left} and \term{right}; one could say,
joins in \nowdb\ are \term{abelian}.

Since the primary key of a type is known
and there is always exactly one field
which is primary key, the foreign join key
(that of \identifier{client}) needs no
explicit mentioning. It is implicitly clear 
that \keyword{join} \identifier{client} \keyword{on origin}
joins on \keyword{origin} $=$ \identifier{client\_key}.

Every edge connects two vertices.
A join, therefore, consists of at most two joins.
The syntax is straightforward:

\keyword{from} \identifier{sales}
\keyword{join} \identifier{client} \keyword{on} \keyword{origin} \\
\hspace*{2cm}\keyword{join} \identifier{product} \keyword{on} \keyword{destin}

With this join, all attributes
from \identifier{sales}, \identifier{client} and \identifier{product}
are available in all clauses.

It may happen that the joined entities
have fields with the same name.
We could have named the primary key in both,
\identifier{client} and \identifier{product},
\identifier{key}, instead of
\identifier{client\_key} and \identifier{prod\_key}.
To distinguish the fields,
one has to use the entity name together with the field name
in the \term{select} clause and (as we will see) in all
other clauses that refer to fields.
Example:

\keyword{select} \identifier{client}.\identifier{key}

Here, using aliases comes in handy, \eg:

\keyword{from} \identifier{sales} \keyword{as} \identifier{s}
\keyword{join} \identifier{client} \keyword{as} \identifier{c} 
               \keyword{on} \keyword{origin} \\
\hspace*{2.8cm}\keyword{join} \identifier{product} \keyword{as} \identifier{p}
                              \keyword{on} \keyword{destin}

In the \term{select} clause, we can now refer to fields
with the alias instead of the full entity name, \eg:

\keyword{select} \identifier{c}.\identifier{key},
                 \identifier{p}.\identifier{key}

\comment{
Joins are the very heart of any database technology --
but it is not easy to get them right with good performance.
In a first approach I tried to make joins work
by always using index range scans.
Unfortunately, it turned out that index range scans
are not very efficient in most (or at least many) cases.
I am therefore looking for alternatives.
There are many, sometimes quite sophisticated, techniques.
Currently, I am experimenting with cache-based subqueries,
which looks promising. Joins can therefore be available
within a short time frame. (And this is indeed one of the most
urgent items on the to-do list.)
}

\subsection{Correlation} 
Correlation combines two or more edges.
\comment{I believe that correlation is much better placed
in support libraries of high-level languages than in \sql.
Some input from an expert would help ;-)}

\subsection{Where Clause}\label{subsec_where}
The \term{where} clause adds criteria for the selection
of specific rows. \term{where} clauses can be very complex.
Indeed, a \term{where} clause is one complex \term{Boolean} expression.

A very simple \term{where} clause would be:

\keyword{where} \identifier{prod\_key} = 100001

Which evaluates to true for all rows that have $100001$
as \identifier{prod\_key}.

Since \term{where} clauses are Boolean expressions,
it is possible to use the Boolean operators
\keyword{and}, \keyword{or} and \keyword{not}.
The first two operators are binary, \ie\
they expect two operands (which again are
Boolean expressions), while \keyword{not}
is unary and expects one operand (which again
is a Boolean expression).

Example:

\keyword{where} \identifier{destin} = 100001
\keyword{and} \identifier{timestamp} $\le$ '2018-04-01'

Before we look at more interesting cases,
let's assume the following set of data:

\begin{minipage}{\textwidth}
\begin{verbatim}
|---------+--------------|
| destin  | timestamp    |
|---------+--------------|
| 100001  | '2018-03-15' |
| 100002  | '2018-03-15' |
| 100001  | '2018-04-15' |
| 100002  | '2018-04-15' |
| 100001  | '2018-05-15' |
| 100002  | '2018-05-15' |
| 100001  | '2018-06-15' |
| 100002  | '2018-06-15' |
|----------+-------------|
\end{verbatim}
\end{minipage}

Here is a tricky \keyword{where} clause:

\keyword{where} \identifier{destin} = 100001
\keyword{and} \identifier{timestamp} $<$ '2018-04-01'
\keyword{or} \identifier{timestamp} $\ge$ '2018-05-01'

\keyword{or} has precedence over \keyword{and}.
Both, \keyword{or} and \keyword{and}, bind to the left,
\ie\ the first operand is the one in front of the operator.

That means, here, that \keyword{or} is at the top-level:
The clause selects all rows that have \keyword{timestamp}
$\ge$ May, 1, and those that have \keyword{destination} $100001$
and \keyword{timestamp} less than April, 1.
In other words, what we see is

\begin{minipage}{\textwidth}
\begin{verbatim}
|---------+--------------|
| destin  | timestamp    |
|---------+--------------|
| 100001  | '2018-03-15' |
| 100001  | '2018-05-15' |
| 100002  | '2018-05-15' |
| 100001  | '2018-06-15' |
| 100002  | '2018-06-15' |
|----------+-------------|
\end{verbatim}
\end{minipage}

This might be surprising at the first glance.
But, indeed, most \sql\ dialects follow this convention.

To force another binding, parentheses can be used:

\begin{minipage}{\textwidth}
\keyword{where} \keyword{destin} = 100001 \\
\hspace*{0.45cm}\keyword{and} (\keyword{timestamp} $<$ '2018-04-01'
\keyword{or} \keyword{timestamp} $\ge$ '2018-05-01')
\end{minipage}

This clause would now select all rows
that have \keyword{destination} $100001$ and
a \keyword{timestamp} that is not in April,
like this:

\begin{minipage}{\textwidth}
\begin{verbatim}
|---------+--------------|
| destin  | timestamp    |
|---------+--------------|
| 100001  | '2018-03-15' |
| 100001  | '2018-05-15' |
| 100001  | '2018-06-15' |
|----------+-------------|
\end{verbatim}
\end{minipage}

Equivalent to this second clause is

\keyword{where} \identifier{destin} = 100001 \\
\hspace*{0.45cm}\keyword{and} \keyword{not} 
(\keyword{timestamp} $\ge$ '2018-04-01'
\keyword{and} \keyword{timestamp} $<$ '2018-05-01')

\keyword{or} and \keyword{and} have precedence
over \keyword{not}; \keyword{not} binds to the right,
\ie\ \keyword{not} is a \term{prefix}.

Would we again leave out the parentheses,
like this:

\keyword{where} \identifier{destin} = 100001 \\
\hspace*{0.45cm}\keyword{and} \keyword{not} 
\keyword{timestamp} $\ge$ '2018-04-01'
\keyword{and} \keyword{timestamp} $<$ '2018-05-01'

we would select all rows that have \keyword{destination}
$100001$ and not a \keyword{timestamp} greater April
and that are before May, hence:

\begin{minipage}{\textwidth}
\begin{verbatim}
|---------+--------------|
| destin  | timestamp    |
|---------+--------------|
| 100001  | '2018-03-15' |
|----------+-------------|
\end{verbatim}
\end{minipage}

\subsection{While Clause}
The \term{while} clause implements a common requirement
in graph databases, namely to follow a link recursively.
A typical example is social networks where we want to
know if $A$ is connected to $B$ through a path spanning
more than one edge (of the same kind).
Here is an illustration:

\begin{minipage}{\textwidth}
\keyword{select} \keyword{true}
\keyword{from} \identifier{friend} \\
\keyword{where} \keyword{edge} $=$ 'isfriend' \\
\keyword{while} \keyword{destin} $\neq$ 12345 
\end{minipage}

This statement would follow the ``isfriend'' edges
until an edge with destination $12345$ is reached.

\comment{
This is not yet available -- and there are some
aspects to clarify: First, the number of iterations
must be bounded; otherwise we may follow a
cycle for eternity. Second, this, obviously, works
only for edges where origin and destination
have the same type. Interesting
may be cases where the types of origin and
destination alternate, \eg\
\identifier{client} `buys' \identifier{product} and
\identifier{product} \keyword{passive}(`buys') \identifier{client}.
The `operator' \term{passive} here would turn the edge around:
we first go from \identifier{client} to \identifier{product}
and then from \identifier{product} to (another) \identifier{client}.
With this, however, a new difficulty arises:
how to avoid the combinatorial explosion after some,
in fact very few, iterations?
More efficient for such cases is probably just to loop
through all edges.
}

\subsection{Group Clause}\label{sec_group}
Grouping partitions the result set
according to a set of \term{keys}.
The result set will then be presented
according to these partitions.
The keys used to partition the set
are defined in the \term{group} clause.
A simple \term{group} clause could be:

\keyword{group by} \keyword{edge, destin}

This clause would partition the result
according to \keyword{edge} and \keyword{destin}.

In the simplest form a statement with
group clause could look like this:

\keyword{select} \keyword{edge},
                 \keyword{destin}
\keyword{from} \identifier{sales}
\keyword{group by} \keyword{edge, destin}

Let's consider the following set of data

\begin{minipage}{\textwidth}
\begin{verbatim}
|----------+---------+--------------|
| edge     | destin  | timestamp    |
|----------+---------+--------------|
| 'buys'   | 100001  | '2018-03-15' |
| 'buys'   | 100002  | '2018-03-15' |
| 'buys'   | 100001  | '2018-04-15' |
| 'buys'   | 100002  | '2018-04-15' |
| 'buys'   | 100001  | '2018-05-15' |
| 'buys'   | 100002  | '2018-05-15' |
| 'buys'   | 100001  | '2018-06-15' |
| 'steals' | 100002  | '2018-06-15' |
|----------+----------+-------------|
\end{verbatim}
\end{minipage}

Applied to this set,
the group above would produce the following output

\begin{minipage}{\textwidth}
\begin{verbatim}
|----------+---------|
| edge     | destin  |
|----------+---------|
| 'buys'   | 100001  |
| 'buys'   | 100002  |
| 'steals' | 100002  |
|----------+---------|
\end{verbatim}
\end{minipage}

It, hence, produces a set of distinct key values.
One could say that grouping \emph{abstracts} or \emph{reduces}
the data set according to the keys.
This, in itself, is often a useful feature,
\viz\ when we want to apply a certain processing
only once per key. As an aside it may be mentioned
that this kind of grouping is extremely fast in \nowdb;
for performance considerations in general, please
refer to chapter \ref{chpt_opt}.

The real power of grouping becomes evident
when we let the database do the processing.
This is the purpose of aggregate functions
(please refer to section \ref{sec_agg} for details).

The aggregate functions go to the \term{select} clause
behind the grouping keys:

\keyword{select} \keyword{edge},
                 \keyword{destin},
                 \identifier{count}($\ast$)
\keyword{from} \identifier{sales}
\keyword{group by} \keyword{edge, destin}

This would now produce:

\begin{minipage}{\textwidth}
\begin{verbatim}
|----------+---------+-------|
| edge     | destin  | count |
|----------+---------|-------|
| 'buys'   | 100001  |  4    |
| 'buys'   | 100002  |  3    |
| 'steals' | 100002  |  1    |
|----------+---------+-------|
\end{verbatim}
\end{minipage}

The \term{group} clause has strong interdependencies
with the \term{select} clause.
In particular, the \term{select} clause must
contain precisely those fields mentioned in the
\term{group} clause and the order of the fields
must be identical. The only things allowed in
the \term{select} clause besides the grouping keys
are aggregates.

The following statements are therefore wrong:

\keyword{select} \keyword{edge}, 
                 \identifier{count}($\ast$)
\keyword{from} \identifier{sales}
\keyword{group by} \keyword{edge, destin}

\keyword{select} \keyword{destin},
                 \keyword{edge}, 
                 \identifier{count}($\ast$)
\keyword{from} \identifier{sales}
\keyword{group by} \keyword{edge, destin}

\keyword{select} \keyword{edge}, 
                 \keyword{destin},
                 'hello world'
\keyword{from} \identifier{sales}
\keyword{group by} \keyword{edge, destin}

Notice that aggregates without grouping
are applied to the whole result set.
For instance, to count all rows in \identifier{sales},
one could say:

\keyword{select} \identifier{count}($\ast$)
\keyword{from} \identifier{sales}

The partition to which \identifier{count} is applied here
is the whole result set.

Syntactically, even this is \acronym{ok}:

\keyword{select} \keyword{edge},
                 \keyword{destin},
                 \identifier{count}($\ast$)
\keyword{from} \identifier{sales}

The values shown for \keyword{edge} and \keyword{destin},
however, have no relation whatsoever to the \identifier{count}
result. They correspond
to any of the rows in the result set,
the first, the last or any other.
That is unspecified.

\comment{
To be discussed: grouping and having.
}

\comment{
Currently, grouping is only possible for combinations of keys
for which an index exists. That is to say:
the index must be defined over the same set of keys
and the order of the keys must be the same.
Otherwise, when there is no matching index,
the query fails with error.
I do not consider this a huge issue.
Grouping is an expensive operation and if,
in an application, grouping is frequently needed,
it should be considered in database design.
However, there a some cases where I am concerned
about performance. In general, the performance
is good or even fantastic. But there are cases
that could motivate alternative grouping techniques.
}

\subsection{Order Clause}
The \term{order} clause sorts the result set
according to a set of sorting criteria (the \term{order keys}).
Its simplest form is just:

\keyword{order by} \keyword{edge}, \keyword{destin}

which would present the result set (whatever it contains)
sorted by \keyword{edge} and \keyword{destin}.

\begin{minipage}{\textwidth}
The statement

\keyword{select} \keyword{edge}, \keyword{destin}
\keyword{from} \identifier{sales}
\keyword{order by} \keyword{edge}, \keyword{destin}
\end{minipage}

applied to the data set already used in section
\ref{sec_group} would produce the following output:

\begin{minipage}{\textwidth}
\begin{verbatim}
|----------+---------+--------------|
| edge     | destin  | timestamp    |
|----------+---------+--------------|
| 'buys'   | 100001  | '2018-03-15' |
| 'buys'   | 100001  | '2018-04-15' |
| 'buys'   | 100001  | '2018-05-15' |
| 'buys'   | 100001  | '2018-06-15' |
| 'buys'   | 100002  | '2018-03-15' |
| 'buys'   | 100002  | '2018-04-15' |
| 'buys'   | 100002  | '2018-05-15' |
| 'steals' | 100002  | '2018-06-15' |
|----------+----------+-------------|
\end{verbatim}
\end{minipage}

Performance considerations are important when dealing with sorting.
It is therefore recommended to study section \ref{chpt_opt} with care.

\comment{
Similar to grouping, ordering works only with an index
that has the same keys in the same order.
Contrary to the grouping case, for ordering this is not acceptable.
Ordering is needed over and over again and good sorting
algorithms must be available in the database.
Well, the algorithms are there (index sorting, in-memory sorting and
external sorting). The question is: how to apply them in
the most efficient manner.
For instance, index sorting is good when we have a range,
otherwise it's bad.
In-memory sorting is good when the result set is small,
otherwise it's bad.
External sorting is always bad, but the last resort.
A special case is ordering by timestamp.
In a timeseries database, that should always be
available!!!
The solution I have in mind is to always create
an index on timestamp with a micro-period (like 1 hour or
1 minute). The rows within one micro-period would be
sorted in memory and, since there are few rows in one
micro-period, that is fast and does not impact latency.
The whole query may be slow, but there are always
data for the caller to make progress.
}

\section{Miscellaneous}
\subsection{Use}
The \term{use} statement sets the database for
the current session. All following statements
 until the next \term{use} statement
will be applied to this database.
Example:

\keyword{use} \identifier{retail}

The statement returns a \term{Status} result.

\subsection{Exec}
The \term{exec} statement executes a stored procedure
whose interface was previously defined.
The simplest form is

\keyword{exec} \identifier{myprocedure}()

In this case \identifier{myprocedure} has no parameters.
A concrete example with parameters may be

\keyword{exec} \identifier{revenue}(9000001, '2018-05-01')

The result of the statement depends on the procedure.
